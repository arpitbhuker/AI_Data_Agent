# ğŸ¤– AI Data Agent â€” Autonomous EDA 

AI Data Agent is an autonomous data analysis assistant that converts a raw CSV dataset into a full analyst-style EDA workflow: column profiling, cleaning decisions, EDA tables, smart visualizations, target-aware analysis, and a polished PDF report â€” along with a modeling-ready .ipynb export.

Instead of manually doing repetitive EDA steps, users can simply upload a dataset and instantly receive structured insights and deliverables.

- dataset profiling (column types, high-null, ID-like, constant columns)
- cleaning + feature engineering summaries
- smart chart selection (only meaningful plots)
- correlation analysis + top relationships
- professional AI-written EDA narrative report
- PDF report export (tables + charts + narrative)
- modeling handoff notebook export (`.ipynb`)

Built for **real-world analyst workflows**, where the goal is not to plot everything, but to generate the **right insights with reasoning**.

---

## ğŸ“Œ Why This Project?

Most EDA tools either:
- generate excessive random charts (noise)
- show raw JSON outputs (not readable)
- fail to produce decision-ready reports
- require manual notebook coding every time

AI Data Agent solves that by behaving like a **junior analyst working autonomously**, producing structured insights & deliverables.

---

## âœ¨ Key Features

## 1) Column Profiling (Dataset Brain)
Before doing anything else, the system profiles the dataset to identify:
- numeric / categorical / datetime-like columns
- constant columns (no value for modeling)
- high-null columns (quality issues)
- ID-like columns (unique ratio too high â†’ usually not useful)

This helps the pipeline decide:
- what to plot
- what to drop
- what needs cleaning attention

## 2) Cleaning Pipeline (Rule-Based Analyst Behavior)
Cleaning includes:
- duplicate removal
- missing value imputation
  - categorical â†’ mode
  - numeric â†’ median
- cleaning report generation with reasoning

## 3) EDA Output as Tables (Not JSON)
Instead of dumping raw dictionaries, EDA is shown as clean tables:
- dataset overview
- missing values table (count + %)
- column dtypes + unique values
- numeric summary (describe + missing)
- correlation matrix
- top correlations table

## 4) Smart Visualization (Minimal but Valuable)
The visualization engine produces only **high-signal plots**:
- top numeric distributions (variance-based)
- correlation heatmap (limited columns â†’ readable)
- strongest numeric relationship scatter plot
- categorical â†’ numeric analysis
  - uses boxplot only when outliers exist
  - groups rare categories into â€œOtherâ€
  - auto-switches orientation for long labels

## 5) AI Narrative Report Writer (Professional Quality)
The LLM is not used for random insight generation.

It is used like a **consultant-style report writer**, producing:

- Executive Summary
- Introduction
- Data Overview
- Data Cleaning
- Summary Statistics
- Missing Values Analysis
- Univariate / Bivariate Findings
- Feature Engineering rationale
- Outliers & Correlation analysis
- Conclusions + Recommendations
- Next Steps

âœ… If evidence is missing for a section, it is removed automatically  
âŒ No filler text like â€œI removed some sectionsâ€¦â€

## 6) Export Deliverables
### ğŸ“„ PDF Report Export
Includes:
- cleaning summary
- assumptions
- EDA tables
- charts
- AI narrative report (structured)

### ğŸ““ Notebook Export (`.ipynb`)
Exports an EDAâ†’modeling notebook styled like Kaggle notebooks, containing:
- cleaning code
- feature engineering code
- EDA steps
- correlation analysis
- target-aware EDA (if target exists)
- modeling starter template

---

## ğŸ—ï¸ Project Architecture
```bash
AI_DATA_AGENT/
â”‚
â”œâ”€â”€ app.py
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ ingestion.py
â”‚   â”œâ”€â”€ profiling.py
â”‚   â”œâ”€â”€ cleaning.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ eda.py
â”‚   â”œâ”€â”€ visualization.py
â”‚   â”œâ”€â”€ assumptions.py
â”‚   â”œâ”€â”€ feature_importance.py
â”‚   â”œâ”€â”€ narrative_builder.py
â”‚   â”œâ”€â”€ report_schema.py
â”‚   â”œâ”€â”€ llm_narrator.py
â”‚   â”œâ”€â”€ report.py
â”‚   â””â”€â”€ memory.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ notebook_exporter.py
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ EDA_Report.pdf
â”‚   â””â”€â”€ charts/
â”‚
â””â”€â”€ notebooks/
    â””â”€â”€ eda_to_modeling.ipynb
```

---

## âš™ï¸ Tech Stack

- **Python**
- **Streamlit** â€” UI frontend
- **Pandas / NumPy** â€” data processing
- **Matplotlib / Seaborn** â€” charts
- **ReportLab** â€” PDF generation (tables + charts)
- **OpenRouter (Llama 3.1 8B Instruct)** â€” AI narrative generation
- **nbformat** â€” notebook generation
- **Rule-based intelligence** for profiling + chart decision

---

## ğŸš€ How It Works (Workflow)

1. Upload dataset (`.csv`)
2. Dataset profiling selects meaningful columns & risks
3. Cleaning is applied (duplicates + missing)
4. EDA tables are generated
5. Smart visualizations are selected
6. Narrative is written by LLM from compressed evidence
7. PDF report export with tables + charts + narrative
8. Notebook export for modeling handoff

---

## âœ… Installation

### 1) Clone the repository
```bash
git clone https://github.com/<your-username>/AI-Data-Agent.git
cd AI-Data-Agent
```

### 2) Create environment
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

### 3) Install dependencies
```bash
pip install -r requirements.txt
```

### 4) Add API Key
In utils/config.py:
```bash
OPENAI_API_KEY = "YOUR_OPENROUTER_KEY"
```

### 5) Run the app
```bash
streamlit run app.py
```

---

## ğŸ“Œ Example Outputs

- âœ… Cleaned dataset preview
- âœ… Profiling summary (expandable)
- âœ… EDA tables (missing, dtypes, summary, correlations)
- âœ… Relevant charts only (not spam)
- âœ… Report-quality narrative
- âœ… PDF Export with full structure
- âœ… Kaggle-style exported notebook

---

## ğŸ”® Future Improvements

- RAG-based industry-specific EDA recommendations
(ex: finance, healthcare, retail templates)
- Add anomaly detection module
- Add drift monitoring for repeated datasets
- Add SHAP-based explainability after modeling
- Add multi-agent planner to make LLM truly agentic
- Add dataset schema-based feature engineering suggestions
- Add auto-detect target column (optional)

---

## âœ… Pros & Cons
### Pros

- âœ… End-to-end automation
- âœ… Smart plot selection (not generic chart spam)
- âœ… Deliverables: PDF + Notebook
- âœ… Professional narrative style
- âœ… Extensible agent architecture

### Cons

- âš ï¸ Not a fully autonomous agent planner yet
- âš ï¸ Narrative depends on LLM quality + prompt tuning
- âš ï¸ Rule-based profiling may need tuning per dataset type

---

ğŸ‘¤ Author

Arpit
- (AI & ML) | Data Science + Data Analysis
- ğŸ”— GitHub: https://github.com/arpitbhuker/
- ğŸ”— LinkedIn: https://www.linkedin.com/in/arpitbhuker/
